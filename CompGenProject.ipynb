{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krO05I-Q7tBY"
      },
      "source": [
        "# Marisa Trie Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z2Lyl1tB7p0t"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBTFuweun7xE"
      },
      "outputs": [],
      "source": [
        "class PatriciaTrieNode():\n",
        "    def __init__(self, key=\"\"):\n",
        "        self.key = key\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False\n",
        "\n",
        "class PatriciaTrie():\n",
        "  def  __init__(self):\n",
        "    self.root = PatriciaTrieNode()\n",
        "  def insert(self, word):\n",
        "    current = self.root\n",
        "    while word:\n",
        "      for key in list(current.children.keys()):\n",
        "        common_prefix_length = self._common_prefix_length(word, key)\n",
        "        if common_prefix_length > 0:\n",
        "          if common_prefix_length < len(key):\n",
        "            existing_node = current.children.pop(key)\n",
        "            new_node = PatriciaTrieNode(key[:common_prefix_length])\n",
        "            current.children[new_node.key] = new_node\n",
        "            new_node.children[key[common_prefix_length:]] = existing_node\n",
        "            existing_node.key = key[common_prefix_length:]\n",
        "\n",
        "            if common_prefix_length == len(word):\n",
        "              new_node.is_end_of_word = True\n",
        "            else:\n",
        "              new_node.children[word[common_prefix_length:]] = PatriciaTrieNode(word[common_prefix_length:])\n",
        "              new_node.children[word[common_prefix_length:]].is_end_of_word = True\n",
        "            return\n",
        "            word = word[common_prefix_length:]\n",
        "            current = current.children[key]\n",
        "            break\n",
        "        else:\n",
        "          current.children[word] = PatriciaTrieNode(word)\n",
        "          current.children[word].is_end_of_word = True\n",
        "          return\n",
        "\n",
        "  def search(self, word):\n",
        "    current = self.root\n",
        "    while word:\n",
        "      found = False\n",
        "      for key, node in current.children.items():\n",
        "        if word.startswith(key):\n",
        "          if len(key) == len(word):\n",
        "            return node.is_end_of_word\n",
        "          word = word[len(key):]\n",
        "          current = node\n",
        "          found = True\n",
        "          break\n",
        "      if not found:\n",
        "        return False\n",
        "    return current.is_end_of_word\n",
        "\n",
        "  def delete(self, word):\n",
        "    def _delete(node, word):\n",
        "      if not word:\n",
        "        if not node.is_end_of_word:\n",
        "          return False\n",
        "        node.is_end_of_word = False\n",
        "        return len(node.children) == 0\n",
        "\n",
        "      for key, child in list(node.children.items()):\n",
        "        if word.startswith(key):\n",
        "          if _delete(child, word[len(key):]):\n",
        "            del node.children[key]\n",
        "            return not node.is_end_of_word and len(node.children) == 0\n",
        "          return False\n",
        "      return False\n",
        "\n",
        "    _delete(self.root, word)\n",
        "\n",
        "  def _common_prefix_length(self, str1, str2):\n",
        "    i = 0\n",
        "    while i < len(str1) and i < len(str2) and str1[i] == str2[i]:\n",
        "      i += 1\n",
        "    return i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Patricia Tree Attempt 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PatriciaTrieNode():\n",
        "    def __init__(self, key=\"\"):\n",
        "        self.key = key\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False\n",
        "\n",
        "class PatriciaTrie():\n",
        "    def __init__(self):\n",
        "        self.root = PatriciaTrieNode()\n",
        "\n",
        "    def insert(self, word):\n",
        "        current = self.root\n",
        "        while word:\n",
        "            found = False\n",
        "            for key in list(current.children.keys()):\n",
        "                common_prefix_length = self._common_prefix_length(word, key)\n",
        "                \n",
        "                if common_prefix_length > 0:\n",
        "                    # Case 1: If the common prefix is shorter than the existing key, split the node\n",
        "                    if common_prefix_length < len(key):\n",
        "                        existing_node = current.children.pop(key)\n",
        "                        new_node = PatriciaTrieNode(key[:common_prefix_length])\n",
        "                        current.children[new_node.key] = new_node\n",
        "                        new_node.children[key[common_prefix_length:]] = existing_node\n",
        "                        existing_node.key = key[common_prefix_length:]\n",
        "\n",
        "                    # Case 2: Update current node to handle the new word\n",
        "                    current = current.children[key[:common_prefix_length]]\n",
        "                    word = word[common_prefix_length:]\n",
        "\n",
        "                    # Case 3: If the word length matches, mark it as an end of word\n",
        "                    if not word:\n",
        "                        current.is_end_of_word = True\n",
        "                    else:\n",
        "                        # Create a new node for the remaining part of the word\n",
        "                        if word not in current.children:\n",
        "                            current.children[word] = PatriciaTrieNode(word)\n",
        "                            current.children[word].is_end_of_word = True\n",
        "                    return\n",
        "                \n",
        "            # Case 4: If no common prefix, add the word as a new child\n",
        "            current.children[word] = PatriciaTrieNode(word)\n",
        "            current.children[word].is_end_of_word = True\n",
        "            return\n",
        "\n",
        "    def search(self, word):\n",
        "        current = self.root\n",
        "        while word:\n",
        "            found = False\n",
        "            for key, node in current.children.items():\n",
        "                if word.startswith(key):\n",
        "                    if len(key) == len(word):\n",
        "                        return node.is_end_of_word\n",
        "                    word = word[len(key):]\n",
        "                    current = node\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                return False\n",
        "        return current.is_end_of_word\n",
        "\n",
        "    def delete(self, word):\n",
        "        def _delete(node, word):\n",
        "            if not word:\n",
        "                if not node.is_end_of_word:\n",
        "                    return False\n",
        "                node.is_end_of_word = False\n",
        "                return len(node.children) == 0\n",
        "\n",
        "            for key, child in list(node.children.items()):\n",
        "                if word.startswith(key):\n",
        "                    if _delete(child, word[len(key):]):\n",
        "                        del node.children[key]\n",
        "                        return not node.is_end_of_word and len(node.children) == 0\n",
        "                    return False\n",
        "            return False\n",
        "\n",
        "        _delete(self.root, word)\n",
        "\n",
        "    def _common_prefix_length(self, str1, str2):\n",
        "        i = 0\n",
        "        while i < len(str1) and i < len(str2) and str1[i] == str2[i]:\n",
        "            i += 1\n",
        "        return i"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qDezOlHzWwU"
      },
      "source": [
        "Alan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acEnNS6iso9b"
      },
      "source": [
        "# Plan\n",
        "1. Implement the Patricia Trie\n",
        "2. Compare how it stores a single genome (GRCh38) in terms of size\n",
        "    - potentially explore size compression of input strings here?\n",
        "3. Compare the time tradeoff to construct the sketch\n",
        "4. Compute phylogenetic distance between two sketches\n",
        "\n",
        "\n",
        "\n",
        "## Tools to Compare against\n",
        "- Python dictionary -> naive\n",
        "- Python implementation of trie\n",
        "- Python implementation of Marisa trie\n",
        "- Python implementation of radix trie\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AqHHhmKuycd",
        "outputId": "52d75bd1-de6e-4cbf-91a7-0f97e65e74b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=97b1602c32e28c5ed968d731022f8c1c03b62e4c11b23983d03a6530ab00176f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Mounted at /content/drive\n",
            "--2024-11-08 21:49:15--  ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.fna.gz\n",
            "           => ‘/content/drive/MyDrive/GRCh38/GRCh38_chr1.fna.gz’\n",
            "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.13, 130.14.250.31, 130.14.250.7, ...\n",
            "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.13|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13 ... done.\n",
            "==> SIZE GCF_000001405.39_GRCh38.p13_genomic.fna.gz ... 964894122\n",
            "==> PASV ... done.    ==> RETR GCF_000001405.39_GRCh38.p13_genomic.fna.gz ... done.\n",
            "Length: 964894122 (920M) (unauthoritative)\n",
            "\n",
            "GCF_000001405.39_GR 100%[===================>] 920.19M  11.8MB/s    in 59s     \n",
            "\n",
            "2024-11-08 21:50:15 (15.5 MB/s) - ‘/content/drive/MyDrive/GRCh38/GRCh38_chr1.fna.gz’ saved [964894122]\n",
            "\n",
            "Genome files downloaded to: /content/drive/MyDrive/GRCh38\n"
          ]
        }
      ],
      "source": [
        "# prompt: download grch38 genome from ftp into google drive\n",
        "\n",
        "!pip install wget\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a directory in Google Drive to store the genome\n",
        "drive_dir = \"/content/drive/MyDrive/GRCh38\"  # Change this to your desired directory\n",
        "if not os.path.exists(drive_dir):\n",
        "    os.makedirs(drive_dir)\n",
        "\n",
        "# Download the GRCh38 genome (replace with the actual FTP link)\n",
        "# Example using wget:\n",
        "# You'll need to find the correct FTP link to the GRCh38 genome files you need.\n",
        "# This example assumes you want to download the chromosome 1 fasta file.\n",
        "# Replace with the appropriate URL\n",
        "!wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.fna.gz -O \"/content/drive/MyDrive/GRCh38/GRCh38_chr1.fna.gz\"\n",
        "\n",
        "# You'll likely want to download multiple files. Adapt this to loop through the needed files and save them properly\n",
        "# Example:\n",
        "# for i in range(1, 23):\n",
        "#   !wget ftp://<correct ftp address for chromosome {i}> -O \"/content/drive/MyDrive/GRCh38/GRCh38_chr{i}.fna.gz\"\n",
        "# # Download other genome files as needed\n",
        "# ...\n",
        "\n",
        "print(f\"Genome files downloaded to: {drive_dir}\")\n",
        "\n",
        "# Unzip (if needed):\n",
        "!gunzip \"/content/drive/MyDrive/GRCh38/GRCh38_chr1.fna.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3PJhq_r4D7G",
        "outputId": "b48fbaa8-f1bb-4faf-c13a-3c82efece214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyfaidx in /usr/local/lib/python3.10/dist-packages (0.8.1.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from pyfaidx) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyfaidx) (24.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->pyfaidx) (3.20.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyfaidx\n",
        "from pyfaidx import Fasta\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWd2qzCAzGrF"
      },
      "outputs": [],
      "source": [
        "# loading k-mers from index into the sketch\n",
        "def build_kmer_index(genome_file, obj, k):\n",
        "    \"\"\"\n",
        "    Reads a genome file, extracts all k-mers of length k, and adds them to the given object.\n",
        "\n",
        "    Parameters:\n",
        "    genome_file (str): Path to the genome file in FASTA format.\n",
        "    obj (object): An object with `insert`, `search`, and `delete` methods.\n",
        "    k (int): Length of k-mer to extract and add to the object.\n",
        "    \"\"\"\n",
        "    # Open the genome file with pyfaidx\n",
        "    genome = Fasta(genome_file)\n",
        "\n",
        "    # Loop over each chromosome or sequence in the genome file\n",
        "    for record in genome:\n",
        "        sequence = str(record)  # Get the sequence as a string\n",
        "        seq_len = len(sequence) - k + 1  # Number of k-mers in this sequence\n",
        "\n",
        "        # Use tqdm to show progress for the k-mer extraction\n",
        "        for i in tqdm(range(seq_len), desc=f\"Processing {record.name}\"):\n",
        "            kmer = sequence[i:i + k]\n",
        "            obj.insert(kmer)\n",
        "\n",
        "    print(f\"All {k}-mers have been added to the object.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0jj_3gDsmfz"
      },
      "outputs": [],
      "source": [
        "## Naive Approach\n",
        "class NaiveSketch():\n",
        "    def __init__(self):\n",
        "        self.dict = {}\n",
        "\n",
        "    def insert(self, word):\n",
        "        self.dict[word] = self.dict.get(word, 0) + 1\n",
        "\n",
        "    def search(self, word):\n",
        "        return self.dict[word]\n",
        "\n",
        "    def delete(self, word):\n",
        "        self.dict[word] = self.dict.get(word, 1) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "pJEZ3Fvbyjrz",
        "outputId": "56e0a4b7-2f71-45f2-b7a9-9f3955d2e893"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'NaiveSketch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e6277aa9e9b2>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create an instance of the Naive dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnaive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveSketch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Build the k-mer index using the naive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NaiveSketch' is not defined"
          ]
        }
      ],
      "source": [
        "genome_file = \"/content/drive/MyDrive/GRCh38/GRCh38_chr1.fna\"  # Path to your GRCh38 genome file\n",
        "k = 21  # Set your desired k-mer length\n",
        "\n",
        "# Create an instance of the Naive dict\n",
        "naive = NaiveSketch()\n",
        "\n",
        "# Build the k-mer index using the naive\n",
        "build_kmer_index(genome_file, naive, k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM5F7LS_zZiz"
      },
      "source": [
        "Amy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-nBdP_OzbYk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33U_0sVjzb3z"
      },
      "source": [
        "Emma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV5HBEONzd2T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1PVOJIQzc5X"
      },
      "source": [
        "Renee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSnkT0mAzem6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
